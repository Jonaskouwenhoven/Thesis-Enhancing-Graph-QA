{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "import json\n",
    "import openai\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from openai import OpenAI\n",
    "openai.api_key = \"ADD YOUR API KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"ADD YOUR API KEY\"\n",
    "client = OpenAI()\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def exact_openai_token_count(text):\n",
    "\t# Initialize the GPT-2 tokenizer\n",
    "\ttokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "\t# Tokenize the text and count the number of tokens\n",
    "\ttokens = tokenizer.encode(text)\n",
    "\n",
    "\treturn len(tokens)\n",
    "\n",
    "def get_info(table_id: str) -> str:\n",
    "\t\n",
    "\t\n",
    "\turl = f\"https://opendata.cbs.nl/ODataFeed/odata/{table_id}/TableInfos?$format=json\"\n",
    "\tresponse = requests.get(url)\n",
    "\t\n",
    "\t\n",
    "\tjsonfile = json.loads(response.text)['value'][0]\n",
    "\ttext =  jsonfile['Summary'] + \" \" + jsonfile['ShortDescription']  \n",
    "\n",
    "\treturn  jsonfile['Summary'], jsonfile['Description'] \n",
    "\n",
    "\n",
    "def prompt_chatgpt(doc, model=\"gpt-3.5-turbo-0125\"):\n",
    "\n",
    "\n",
    "\ttemplate = f\"\"\"\n",
    "\t\tYou are provided a table title, its summary, and a description: '{doc}':\n",
    "\n",
    "\t\tBased on this I want you to return the following\n",
    "\t\t- \"Keywords\": List of Keywords and terms that best portray the table.\n",
    "\t\t- \"Summary\": A summary of the table that helps with the understanding \\\\\n",
    "\t\tof the table and is optimized for document retrieval, this summary should not \\\\\n",
    "\t\tcontain more than 75 words. \n",
    "\t\"\"\"\n",
    "\n",
    "\tinput_tokens = exact_openai_token_count(template)\n",
    "\tinput_cost = input_tokens / 1000 * 0.0005   # Cost per 1K tokens for input\n",
    "\n",
    "\t\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t\tmodel=model,    \n",
    "\t\tresponse_format={\"type\": \"json_object\"},\n",
    "\t\tmessages=[\n",
    "\t\t\t{\"role\": \"system\", \"content\": \"Based on a table description you generate a list of keywords and a Summary in a document retrieval optimized format. In the Dutch Language, in a json file\"},\n",
    "\t\t\t{\"role\": \"user\", \"content\": template}\n",
    "\t\t],\n",
    "\t\ttemperature=0.0,\n",
    "\n",
    "\t)\n",
    "\toutput = json.loads(response.choices[0].message.content)\n",
    "\toutput_tokens = exact_openai_token_count(f\"{output}\")\n",
    "\toutput_cost = output_tokens / 1000 * 0.0015  # Cost per 1K tokens for output\n",
    "\n",
    "\t# Calculate the total cost by adding input and output costs\n",
    "\ttotal_cost = input_cost + output_cost\n",
    "\n",
    "\t# # Print the costs\n",
    "\t# print(f\"Input tokens: {input_tokens}, Cost: ${input_cost:.4f}\")\n",
    "\t# print(f\"Output tokens: {output_tokens}, Cost: ${output_cost:.4f}\")\n",
    "\t# print(f\"Total cost: ${total_cost:.4f}\")\n",
    "\treturn output, total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabledf = pd.read_pickle(\"data/tabledf.pkl\")\n",
    "measure_df = pd.read_pickle(\"data/measure_dimensions_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "keywords, summaries = [], []\n",
    "for index, row in tabledf[:1].iterrows():\n",
    "    table_title = row['Table Title']\n",
    "\n",
    "    measures = list(row['Measure'])\n",
    "    ## take random 3 measures\n",
    "    if len(measures) > 5:\n",
    "        selected_measures = random.sample(measures, 5)\n",
    "\n",
    "    else:\n",
    "        selected_measures = measures\n",
    "\n",
    "\n",
    "    measure_string = \"De tabel heeft de volgende karakteristieken:\"\n",
    "\n",
    "    for measure in selected_measures:\n",
    "        try:\n",
    "            measure_df_row = measure_df[measure_df['id'] == measure]\n",
    "            title = measure_df_row['title'].values[0]\n",
    "\n",
    "            measure_string += f\" {title},\"\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "    ## need to fetch table summary and short description\n",
    "\n",
    "    summary, desc = get_info(row['table_id'])\n",
    "\n",
    "\n",
    "    final_prompt = f\"Voor de tabel met de titel '{table_title}', de volgende karakteristieken: {measure_string} en omschrijving {summary}\"\n",
    "\n",
    "    answer, cost = prompt_chatgpt(final_prompt)\n",
    "    keywords.append(answer['Keywords'])\n",
    "    summaries.append(answer['Summary'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
